Задача - составить частотный словарь слов, используя набор файлов, в
количестве не более чем 256.

Программа должна считывать несколько (до 256) текстовых файлов, разбивая
текст на слова, и для каждого слова подсчитывать количество появлений в
тексте. Словом считать последовательность символов, начинающуюся с буквы и
состоящую из букв и цифр, например abc, alpha, d123s, continent, s1d2f3.
 Словоформы не анализировать, т.е. морфология не учитывается.
Слова с различными окончаниями (за счет падежа, числа или склонения)
считать разными. Все слова должны быть приведены к нижнему регистру
(малые буквы).
Файлы находятся в каталоге "texts".
Вход программы - список файлов, которые необходимо обработать, передается через
параметры командной строки.
Выход программы - ДВА ФАЙЛА, с частотными словарями, упорядоченными в
первом файле - по словам в алфавитном порядке,
во втором файле - по частоте (в порядке убывания).

Алгоритм должен быть однопроходным, без повторного считывания 
информации из файлов.

Использовать статический  массив структур вида

typedef struct word {
  int count;
  char *w;
} WORD;

WORD *words[100000] ;

При добавлении НОВОГО слова в массив использовать функцию malloc (читайте справочники !!!)
для создания новой записи w в структуре  WORD[N], являющейся элементом массива *words.
Всегда используйте sizeof для определения размера переменных или структур (strlen для строк).
Для передачи входа в программу используйте параметры функции main, - первый из них
содержит количество передаваемых имен файлов, второй является массивом указателей на
имена файлов.
Для сортировки использовать библиотечную функцию qsort.
Заготовка файла для текста на английском языке в файле main.c,
для разбивки на слова используется библиотечная функция strtok; 
 При добавлении нового слова сначала нужно создать структуру WORD и связать ее с
указателем в массиве words (это массив указателей на структуры типа WORD).
